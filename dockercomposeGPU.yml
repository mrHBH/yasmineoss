version: '3.9'
services:
  pythonbackend:
    container_name: pythonbackend
    build:
      context: ./backend/python/
      dockerfile: dockerfile.CPU
    restart: unless-stopped
    volumes:
      - ./backend/python/models/:/app/models
      - ./backend/python/src/:/app/src
      - ./tempdir/:/app/tempdir
      - ./frontend/:/app/frontend

    ports:
      - '8000:8000'
    networks:
      - yasminenet
    environment:
      - LLM_MODEL_NAME=Meta-Llama-3-8B-Instruct.Q4_0.gguf
      - LLM_MODELS_PATH=/app/models/
      - LLM_MODEL_URL=https://huggingface.co/NousResearch/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  tsbackend:
    container_name: tsbackend
    build:
      context: ./backend/typescript/
      dockerfile: dockerfile 
    restart: unless-stopped    
    ports:
      - '8089:8089'
    networks:
      - yasminenet

  
  code-server:
    image: lscr.io/linuxserver/code-server:latest
    container_name: code-server
    environment:
      - PUID=0
      - PGID=0
      - TZ=Africa/Nairobi
      - PASSWORD=vs
      - SUDO_PASSWORD=vs
    volumes:
      - ./frontend/public/:/public
      - ./backend:/python/backendpython 
    ports:
      - 8443:8443
    restart: unless-stopped
    networks:
      - yasminenet

  browserfrontend:
    container_name: browserfrontend
    build:
      context: ./frontend/
      dockerfile: Dockerfile
    restart: unless-stopped
    volumes:
      - ./frontend/:/frontend
      - /frontend/node_modules
    ports:
      - '3001:3001'
    networks:
      - yasminenet

  
  ollamabackend:
    image: ollama/ollama:latest
    tty: true

    container_name: ollamabackend
    volumes:
      - ./ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    # entrypoint: 
    #       - bash
    #       - -c
    #       - |
    #         sleep 5           
    #       - ollama pull phi3:3.8b     
    networks:
      - yasminenet
     
    deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                count: all
                capabilities: [gpu]
 
 
  # cppbackend:
  #   container_name: cppbackend
  #   build:
  #     context: ./backend/c++/
  #     dockerfile: Dockerfile
  #   restart: unless-stopped
 
  #   ports:
  #     - '8080:8080'
  #   networks:
  #     - yasminenet


  # # rustbackend:
  # #   container_name: rustbackend
  # #   build:      
  # #     context: ./backend/rust/
  # #     dockerfile: Dockerfile
  # #   restart: unless-stopped 
  # #   ports:
  # #     - '8420:8420'
  # #   networks:
  # #     - yasminenet
  # comfyui:
  #   image: xingren23/comfyui:comfyui-cu121-v1.0.6
  #   container_name: comfyui
  #   restart: unless-stopped
  #   ports:
  #     - '8888:8188'
  #   volumes:
  #     - ./workspace/models/:/workspace/models
  #     - ./workspace/input:/workspace/ComfyUI/input
  #     - ./workspace/output:/workspace/ComfyUI/output
  #   networks:
  #     - yasminenet
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
              
networks:
  yasminenet:

volumes:
  frontend:
  backend:
  tempdir:
  workspace:
